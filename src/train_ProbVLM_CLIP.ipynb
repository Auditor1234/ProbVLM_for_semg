{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2986807e-7850-404f-a957-eaeb16371d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ProgramFiles\\python\\multi_modal\\ProbVLM_for_semg\\src\\train_probVLM.py:26: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\tensor\\python_tensor.cpp:85.)\n",
      "  dtype=torch.cuda.FloatTensor(),\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from os.path import join as ospj\n",
    "from os.path import expanduser\n",
    "from munch import Munch as mch\n",
    "import numpy as np\n",
    "\n",
    "from ds import prepare_coco_dataloaders, prepare_flickr_dataloaders, prepare_cub_dataloaders, prepare_flo_dataloaders\n",
    "\n",
    "from utils import *\n",
    "from networks import *\n",
    "from train_probVLM import *\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbdb7f39-293e-48fe-bd3b-da616157f4a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prepare cub dataset with 150 classes\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:/Download/Datasets/CUB\\\\CUB/text_c10\\\\001.Black_footed_Albatross\\\\Black_Footed_Albatross_0001_796111.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\ProgramFiles\\python\\multi_modal\\ProbVLM_for_semg\\src\\train_ProbVLM_CLIP.ipynb Cell 2\u001b[0m line \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/ProgramFiles/python/multi_modal/ProbVLM_for_semg/src/train_ProbVLM_CLIP.ipynb#W1sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m data_dir \u001b[39m=\u001b[39m ospj(\u001b[39m'\u001b[39m\u001b[39mD:/Download/Datasets/CUB\u001b[39m\u001b[39m'\u001b[39m, dataset) \u001b[39m# e.g. ospj(expanduser('~'), 'Documents', 'jm', 'data', dataset)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/ProgramFiles/python/multi_modal/ProbVLM_for_semg/src/train_ProbVLM_CLIP.ipynb#W1sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m dataloader_config \u001b[39m=\u001b[39m mch({\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/ProgramFiles/python/multi_modal/ProbVLM_for_semg/src/train_ProbVLM_CLIP.ipynb#W1sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mbatch_size\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m64\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/ProgramFiles/python/multi_modal/ProbVLM_for_semg/src/train_ProbVLM_CLIP.ipynb#W1sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mrandom_erasing_prob\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m0.\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/ProgramFiles/python/multi_modal/ProbVLM_for_semg/src/train_ProbVLM_CLIP.ipynb#W1sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtraindata_shuffle\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/ProgramFiles/python/multi_modal/ProbVLM_for_semg/src/train_ProbVLM_CLIP.ipynb#W1sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m })\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/ProgramFiles/python/multi_modal/ProbVLM_for_semg/src/train_ProbVLM_CLIP.ipynb#W1sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m loaders,vocab \u001b[39m=\u001b[39m load_data_loader(dataset, data_dir, dataloader_config)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/ProgramFiles/python/multi_modal/ProbVLM_for_semg/src/train_ProbVLM_CLIP.ipynb#W1sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m cub_train_loader, cub_valid_loader, cub_test_loader \u001b[39m=\u001b[39m loaders[\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m], loaders[\u001b[39m'\u001b[39m\u001b[39mval\u001b[39m\u001b[39m'\u001b[39m], loaders[\u001b[39m'\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[1;32md:\\ProgramFiles\\python\\multi_modal\\ProbVLM_for_semg\\src\\utils.py:116\u001b[0m, in \u001b[0;36mload_data_loader\u001b[1;34m(dataset, data_dir, dataloader_config)\u001b[0m\n\u001b[0;32m    109\u001b[0m prepare_loaders \u001b[39m=\u001b[39m {\n\u001b[0;32m    110\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mcoco\u001b[39m\u001b[39m'\u001b[39m: prepare_coco_dataloaders,\n\u001b[0;32m    111\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mflickr\u001b[39m\u001b[39m'\u001b[39m: prepare_flickr_dataloaders,\n\u001b[0;32m    112\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mCUB\u001b[39m\u001b[39m'\u001b[39m:prepare_cub_dataloaders,\n\u001b[0;32m    113\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mFLO\u001b[39m\u001b[39m'\u001b[39m:prepare_flo_dataloaders\n\u001b[0;32m    114\u001b[0m }[dataset]\n\u001b[0;32m    115\u001b[0m \u001b[39mif\u001b[39;00m dataset \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mCUB\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m--> 116\u001b[0m     loaders \u001b[39m=\u001b[39m prepare_loaders(\n\u001b[0;32m    117\u001b[0m         dataloader_config,\n\u001b[0;32m    118\u001b[0m         dataset_root\u001b[39m=\u001b[39;49mdata_dir,\n\u001b[0;32m    119\u001b[0m         caption_root\u001b[39m=\u001b[39;49mdata_dir\u001b[39m+\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m/text_c10\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m    120\u001b[0m         vocab_path\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mds/vocabs/cub_vocab.pkl\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m    121\u001b[0m \u001b[39melif\u001b[39;00m dataset \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mFLO\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    122\u001b[0m     loaders \u001b[39m=\u001b[39m prepare_loaders(\n\u001b[0;32m    123\u001b[0m         dataloader_config,\n\u001b[0;32m    124\u001b[0m         dataset_root\u001b[39m=\u001b[39mdata_dir,\n\u001b[0;32m    125\u001b[0m         caption_root\u001b[39m=\u001b[39mdata_dir\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m/text_c10\u001b[39m\u001b[39m'\u001b[39m,)\n",
      "File \u001b[1;32md:\\ProgramFiles\\python\\multi_modal\\ProbVLM_for_semg\\src\\ds\\_dataloader.py:301\u001b[0m, in \u001b[0;36mprepare_cub_dataloaders\u001b[1;34m(dataloader_config, dataset_root, caption_root, dataset_name, vocab_path, num_workers)\u001b[0m\n\u001b[0;32m    298\u001b[0m caption_drop_prob \u001b[39m=\u001b[39m dataloader_config\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mcaption_drop_prob\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m0.0\u001b[39m)\n\u001b[0;32m    300\u001b[0m dataloaders \u001b[39m=\u001b[39m {}\n\u001b[1;32m--> 301\u001b[0m dataloaders[\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m _get_cub_loader(\n\u001b[0;32m    302\u001b[0m     image_root, caption_root,\n\u001b[0;32m    303\u001b[0m     train_classes,\n\u001b[0;32m    304\u001b[0m     vocab, num_workers,\n\u001b[0;32m    305\u001b[0m     train\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    306\u001b[0m     omit_ids\u001b[39m=\u001b[39;49momit_ids,\n\u001b[0;32m    307\u001b[0m     cutout_prob\u001b[39m=\u001b[39;49mcutout_prob,\n\u001b[0;32m    308\u001b[0m     caption_drop_prob\u001b[39m=\u001b[39;49mcaption_drop_prob,\n\u001b[0;32m    309\u001b[0m )\n\u001b[0;32m    311\u001b[0m dataloaders[\u001b[39m'\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m _get_cub_loader(\n\u001b[0;32m    312\u001b[0m     image_root, caption_root,\n\u001b[0;32m    313\u001b[0m     val_classes,\n\u001b[0;32m    314\u001b[0m     vocab, num_workers,\n\u001b[0;32m    315\u001b[0m     train\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    316\u001b[0m )\n\u001b[0;32m    318\u001b[0m dataloaders[\u001b[39m'\u001b[39m\u001b[39mval\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m _get_cub_loader(\n\u001b[0;32m    319\u001b[0m     image_root, caption_root,\n\u001b[0;32m    320\u001b[0m     train_classes,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    323\u001b[0m     ids\u001b[39m=\u001b[39momit_ids\n\u001b[0;32m    324\u001b[0m )\n",
      "File \u001b[1;32md:\\ProgramFiles\\python\\multi_modal\\ProbVLM_for_semg\\src\\ds\\_dataloader.py:241\u001b[0m, in \u001b[0;36m_get_cub_loader\u001b[1;34m(image_root, caption_root, data_classes, vocab, num_workers, batch_size, train, omit_ids, ids, cutout_prob, caption_drop_prob)\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_cub_loader\u001b[39m(image_root, caption_root,\n\u001b[0;32m    224\u001b[0m                     data_classes, vocab,\n\u001b[0;32m    225\u001b[0m                     num_workers,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    236\u001b[0m     \u001b[39m#    random_erasing_prob=cutout_prob,\u001b[39;00m\n\u001b[0;32m    237\u001b[0m     \u001b[39m#)\u001b[39;00m\n\u001b[0;32m    239\u001b[0m     _caption_transform \u001b[39m=\u001b[39m tokenize\n\u001b[1;32m--> 241\u001b[0m     cub_dataset \u001b[39m=\u001b[39m CUBCaption(image_root, caption_root,\n\u001b[0;32m    242\u001b[0m                              data_classes,\n\u001b[0;32m    243\u001b[0m                              \u001b[39m#transform=_image_transform,\u001b[39;49;00m\n\u001b[0;32m    244\u001b[0m                              imagenet_transform,\n\u001b[0;32m    245\u001b[0m                              \u001b[39m#caption_transform(vocab, caption_drop_prob),\u001b[39;49;00m\n\u001b[0;32m    246\u001b[0m                              omit_ids\u001b[39m=\u001b[39;49momit_ids,\n\u001b[0;32m    247\u001b[0m                              target_transform\u001b[39m=\u001b[39;49m_caption_transform,\n\u001b[0;32m    248\u001b[0m                              ids\u001b[39m=\u001b[39;49mids)\n\u001b[0;32m    249\u001b[0m     \u001b[39mif\u001b[39;00m train:\n\u001b[0;32m    250\u001b[0m         sampler \u001b[39m=\u001b[39m CUBSampler(cub_dataset, \u001b[39mlen\u001b[39m(cub_dataset\u001b[39m.\u001b[39mtarget_classes))\n",
      "File \u001b[1;32md:\\ProgramFiles\\python\\multi_modal\\ProbVLM_for_semg\\src\\ds\\cub.py:79\u001b[0m, in \u001b[0;36mCUBCaption.__init__\u001b[1;34m(self, image_root, caption_root, target_classes, transform, target_transform, omit_ids, ids)\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m     78\u001b[0m txt_fname \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(caption_root, bird_name, fname\u001b[39m.\u001b[39mreplace(\u001b[39m'\u001b[39m\u001b[39mjpg\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtxt\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m---> 79\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(txt_fname) \u001b[39mas\u001b[39;00m fin:\n\u001b[0;32m     80\u001b[0m     captions \u001b[39m=\u001b[39m [line\u001b[39m.\u001b[39mstrip() \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m fin]\n\u001b[0;32m     82\u001b[0m n_images \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:/Download/Datasets/CUB\\\\CUB/text_c10\\\\001.Black_footed_Albatross\\\\Black_Footed_Albatross_0001_796111.txt'"
     ]
    }
   ],
   "source": [
    "dataset = 'CUB' # coco or flickr\n",
    "data_dir = ospj('D:/Download/Datasets/CUB', dataset) # e.g. ospj(expanduser('~'), 'Documents', 'jm', 'data', dataset)\n",
    "dataloader_config = mch({\n",
    "    'batch_size': 64,\n",
    "    'random_erasing_prob': 0.,\n",
    "    'traindata_shuffle': True\n",
    "})\n",
    "loaders,vocab = load_data_loader(dataset, data_dir, dataloader_config)\n",
    "cub_train_loader, cub_valid_loader, cub_test_loader = loaders['train'], loaders['val'], loaders['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da29997-5483-4fa0-b927-74b38dc36cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clip_net = load_model('cuda')\n",
    "CLIP_Net = load_model(device='cuda', model_path=None)\n",
    "ProbVLM_Net = BayesCap_for_CLIP(\n",
    "    inp_dim=512,\n",
    "    out_dim=512,\n",
    "    hid_dim=256,\n",
    "    num_layers=3,\n",
    "    p_drop=0.05,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1513f40-28d1-4d4d-8d9b-e113c8cd4183",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ProbVLM(\n",
    "    CLIP_Net,\n",
    "    ProbVLM_Net,\n",
    "    cub_train_loader,\n",
    "    cub_valid_loader,\n",
    "    Cri = TempCombLoss(),\n",
    "    device='cuda',\n",
    "    dtype=torch.cuda.FloatTensor,\n",
    "    init_lr=8e-5,\n",
    "    num_epochs=500,\n",
    "    eval_every=5,\n",
    "    ckpt_path='../ckpt/ProbVLM_Net',\n",
    "    T1=1e0,\n",
    "    T2=1e-4\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
